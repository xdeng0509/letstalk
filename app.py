"""
Let's Talk - Webåº”ç”¨åç«¯
ä½¿ç”¨Flaskæä¾›APIæœåŠ¡
"""
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from agents.subject_library import SubjectLibrary
from agents.subject_agent import SubjectAgent
from utils.llm_client import LLMClient
import traceback
import random

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# åˆå§‹åŒ–å­¦ç§‘åº“
subject_library = SubjectLibrary()

# å¯åŠ¨å‚æ•°/ç¯å¢ƒï¼šå¼ºåˆ¶ä»…ç”¨LLMï¼ˆç¦æ­¢æ¼”ç¤ºï¼‰
import os, sys
LLM_ONLY = os.getenv('LLM_ONLY', 'false').lower() in ('1','true','yes')
if '--llm-only' in sys.argv:
    LLM_ONLY = True

# åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒLLM-onlyæ¨¡å¼ï¼‰
try:
    llm_client = LLMClient()
    demo_mode = False
    llm_available = True
except Exception as e:
    print(f"âš ï¸  æ— æ³•è¿æ¥LLM API: {str(e)}")
    if LLM_ONLY:
        # å¼ºåˆ¶ä»…ç”¨LLMæ—¶ï¼Œç›´æ¥é€€å‡ºï¼Œä¸å…è®¸æ¼”ç¤ºæ¨¡å¼
        print("âŒ LLM_ONLY=trueï¼ŒLLMä¸å¯ç”¨ï¼ŒæœåŠ¡é€€å‡ºã€‚")
        sys.exit(1)
    print("LLMä¸å¯ç”¨ï¼Œä½†ç”¨æˆ·å¯ä»¥é€‰æ‹©ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼")
    llm_client = None
    demo_mode = True
    llm_available = False

# ç”¨æˆ·é€‰æ‹©çš„æ¨¡å¼ï¼ˆå¯é€šè¿‡APIåˆ‡æ¢ï¼›LLM-onlyä¸‹å¼ºåˆ¶ä¸ºllmï¼‰
user_mode = 'llm' if LLM_ONLY else 'demo'  # é»˜è®¤demoï¼ŒLLM_ONLYå¼ºåˆ¶llm

@app.route('/')
def landing():
    """äº§å“ä»‹ç»é¦–é¡µ"""
    return render_template('landing.html')

@app.route('/chat')
def chat():
    """å¯¹è¯å…¥å£é¡µ"""
    return render_template('index.html')


@app.route('/api/ask', methods=['POST'])
def ask_question():
    """
    å¤„ç†ç”¨æˆ·æé—®ï¼Œè¿”å›å­¦ç§‘ç›²ç›’å¼€å±€çš„å›ç­”
    
    Request Body:
        {
            "question": "ç”¨æˆ·çš„é—®é¢˜",
            "subject_count": 3  // å¯é€‰ï¼Œé»˜è®¤3ä¸ªå­¦ç§‘
        }
    
    Response:
        {
            "success": true,
            "question": "ç”¨æˆ·çš„é—®é¢˜",
            "subjects": [
                {
                    "name": "å­¦ç§‘åç§°",
                    "icon": "å­¦ç§‘å›¾æ ‡",
                    "answer": "ä¸€å¥è¯å›ç­”",
                    "description": "å­¦ç§‘æè¿°"
                }
            ],
            "demo_mode": false
        }
    """
    try:
        data = request.json
        question = data.get('question', '').strip()
        subject_count = data.get('subject_count', 3)
        
        if not question:
            return jsonify({
                'success': False,
                'error': 'é—®é¢˜ä¸èƒ½ä¸ºç©º'
            }), 400
        
        results = []

        # LLMæ¨¡å¼ä¸‹ï¼šç”¨å¤§æ¨¡å‹é€‰æ‹©æœ€ç›¸å…³çš„Top-Nå­¦ç§‘
        if user_mode == 'llm':
            from copy import deepcopy
            # èšåˆå…¨é‡å­¦ç§‘å€™é€‰
            all_groups = subject_library.get_all_subjects()
            all_subjects = all_groups['hot'] + all_groups['cold'] + all_groups['crossover']
            # æ„é€ é€‰æ‹©æç¤º
            selector_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªå†…å®¹è·¯ç”±å™¨ã€‚æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œä»ä¸‹é¢å­¦ç§‘åˆ—è¡¨ä¸­é€‰å‡ºæœ€ç›¸å…³çš„" + str(subject_count) + "ä¸ªå­¦ç§‘åç§°ï¼ˆä¸­æ–‡ï¼‰ã€‚\n" +
                "ç”¨æˆ·é—®é¢˜ï¼š" + question + "\n\n" +
                "å­¦ç§‘åˆ—è¡¨ï¼š\n" + "\n".join([f"- {s['name']}ï¼š{s['description'][:60]}" for s in all_subjects]) + "\n\n" +
                "åªè¾“å‡ºå­¦ç§‘åç§°ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦ç¼–å·ï¼Œä¸è¦è§£é‡Šã€‚"
            )
            try:
                current_llm = LLMClient()
                selection_text = current_llm.generate_response(selector_prompt, system_prompt=None, max_tokens=200, temperature=0.2)
                selected_names = [x.strip() for x in selection_text.split('\n') if x.strip()]
                # æ˜ å°„ä¸ºå¯¹è±¡å¹¶å»é‡
                name_to_subject = {s['name']: s for s in all_subjects}
                selected_infos = [name_to_subject[n] for n in selected_names if n in name_to_subject]
                # å›é€€ï¼šä¸è¶³åˆ™è¡¥è¶³
                if len(selected_infos) < subject_count:
                    fallback = subject_library.get_smart_subjects(question, count=subject_count, diversity=0.3)
                    # åˆå¹¶å¹¶å»é‡
                    seen = set([s['name'] for s in selected_infos])
                    for s in fallback:
                        if s['name'] not in seen:
                            selected_infos.append(s)
                            seen.add(s['name'])
                            if len(selected_infos) >= subject_count:
                                break
                subjects = selected_infos[:subject_count]
            except Exception as e:
                print(f"[LLM ERROR] subject selection failed: {e}")
                if LLM_ONLY:
                    return jsonify({
                        'success': False,
                        'error': f'LLMå­¦ç§‘è·¯ç”±å¤±è´¥ï¼š{str(e)}',
                        'llm_only': True
                    }), 503
                subjects = subject_library.get_smart_subjects(question, count=subject_count, diversity=0.3)
        else:
            # æ¼”ç¤ºæ¨¡å¼ï¼šä½¿ç”¨æ—¢æœ‰çš„æ™ºèƒ½é€‰æ‹©
            subjects = subject_library.get_smart_subjects(question, count=subject_count, diversity=0.3)
        
        # ä¸ºæ¯ä¸ªå­¦ç§‘ç”Ÿæˆè´´åˆä¸”ç®€çŸ­çš„ä¸€å¥è¯å›ç­”
        for subject_info in subjects:
            current_llm = LLMClient() if user_mode == 'llm' else None
            agent = SubjectAgent(subject_info, current_llm)
            answer = agent.answer_one_sentence(question)
            # LLM_ONLYï¼šå¦‚æœè¯¥å­¦ç§‘å›ç­”å›é€€æ¼”ç¤ºï¼Œåˆ™æ•´ä½“æŠ¥é”™ï¼Œé¿å…æ··å…¥demo
            if LLM_ONLY and getattr(agent, 'last_used_demo', False):
                return jsonify({
                    'success': False,
                    'error': 'LLMè°ƒç”¨å¤±è´¥ï¼Œç›²ç›’å›ç­”å·²ç¦æ­¢æ¼”ç¤ºæ¨¡å¼',
                    'llm_only': True
                }), 503
            results.append({
                'name': subject_info['name'],
                'icon': subject_info['icon'],
                'answer': answer,
                'description': subject_info['description'],
                'display_name': agent.get_display_name(),
                'schools': subject_info.get('schools', []),
                'used_demo': getattr(agent, 'last_used_demo', False)
            })
        
        return jsonify({
            'success': True,
            'question': question,
            'subjects': results,
            'demo_mode': user_mode == 'demo',
            'llm_provider': ('gemini' if isinstance(llm_client, LLMClient) and getattr(llm_client, 'provider', None) == 'gemini' else ('openai' if isinstance(llm_client, LLMClient) and getattr(llm_client, 'provider', None) == 'openai' else ('demo' if user_mode!='llm' else 'unknown')))
        })
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/subjects', methods=['GET'])
def get_all_subjects():
    """
    è·å–æ‰€æœ‰å­¦ç§‘ä¿¡æ¯
    
    Response:
        {
            "success": true,
            "subjects": {
                "hot": [...],
                "cold": [...],
                "crossover": [...]
            }
        }
    """
    try:
        all_subjects = subject_library.get_all_subjects()
        return jsonify({
            'success': True,
            'subjects': all_subjects
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/status', methods=['GET'])
def get_status():
    """
    è·å–ç³»ç»ŸçŠ¶æ€
    
    Response:
        {
            "success": true,
            "demo_mode": false,
            "llm_available": true,
            "current_mode": "demo",
            "subject_count": 20
        }
    """
    all_subjects = subject_library.get_all_subjects()
    total_count = (
        len(all_subjects['hot']) + 
        len(all_subjects['cold']) + 
        len(all_subjects['crossover'])
    )
    
    return jsonify({
        'success': True,
        'demo_mode': demo_mode,
        'llm_available': llm_available,
        'current_mode': user_mode,
        'llm_only': LLM_ONLY,
        'subject_count': total_count
    })


@app.route('/api/set-mode', methods=['POST'])
def set_mode():
    """
    è®¾ç½®è¿è¡Œæ¨¡å¼
    
    Request Body:
        {
            "mode": "demo" or "llm"
        }
    
    Response:
        {
            "success": true,
            "mode": "demo",
            "message": "å·²åˆ‡æ¢åˆ°æ¼”ç¤ºæ¨¡å¼"
        }
    """
    global user_mode
    
    try:
        data = request.json
        mode = data.get('mode', 'demo').lower()
        
        if mode not in ['demo', 'llm']:
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„æ¨¡å¼ï¼Œè¯·é€‰æ‹© demo æˆ– llm'
            }), 400
        
        # LLM-only æ¨¡å¼ä¸‹ç¦æ­¢åˆ‡æ¢åˆ° demo
        if LLM_ONLY and mode == 'demo':
            return jsonify({
                'success': False,
                'error': 'LLM_ONLY æ¨¡å¼ä¸‹ç¦æ­¢æ¼”ç¤ºæ¨¡å¼'
            }), 400
        
        if mode == 'llm' and not llm_available:
            return jsonify({
                'success': False,
                'error': 'LLMæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIé…ç½®'
            }), 400
        
        user_mode = mode
        
        message = 'å·²åˆ‡æ¢åˆ°LLMæ¨¡å¼' if mode == 'llm' else 'å·²åˆ‡æ¢åˆ°æ¼”ç¤ºæ¨¡å¼'
        
        return jsonify({
            'success': True,
            'mode': user_mode,
            'message': message,
            'llm_only': LLM_ONLY
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/deep-chat', methods=['POST'])
def deep_chat():
    """
    æ·±å…¥å•èŠï¼šä¸å•ä¸ªå­¦ç§‘è¿›è¡Œæ·±åº¦å¯¹è¯
    
    Request Body:
        {
            "question": "ç”¨æˆ·çš„é—®é¢˜",
            "subject_name": "å­¦ç§‘åç§°",
            "context": "ä¹‹å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰"
        }
    
    Response:
        {
            "success": true,
            "subject": "å­¦ç§‘åç§°",
            "answer": "è¯¦ç»†å›ç­”ï¼ˆ3-5å¥è¯ï¼‰",
            "suggestions": ["å»ºè®®é—®é¢˜1", "å»ºè®®é—®é¢˜2", "å»ºè®®é—®é¢˜3"],
            "schools": [...]  // è¯¥å­¦ç§‘çš„æ´¾åˆ«åˆ—è¡¨
        }
    """
    try:
        data = request.json
        question = data.get('question', '').strip()
        subject_name = data.get('subject_name', '').strip()
        context = data.get('context', '')
        
        if not question or not subject_name:
            return jsonify({
                'success': False,
                'error': 'é—®é¢˜å’Œå­¦ç§‘åç§°ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # è·å–å­¦ç§‘ä¿¡æ¯
        subject_info = subject_library.get_subject_by_name(subject_name)
        if not subject_info:
            return jsonify({
                'success': False,
                'error': f'æœªæ‰¾åˆ°å­¦ç§‘ï¼š{subject_name}'
            }), 404
        
        # åˆ›å»ºâ€œæ¯æ¬¡å•èŠä¸“ç”¨â€çš„ LLM å®¢æˆ·ç«¯ï¼ˆçœŸå®æ¨¡å‹å¯¹è¯ï¼‰ï¼Œå¹¶æŒ‰éœ€è¦è¦†ç›– persona
        from copy import deepcopy
        subject_info_override = deepcopy(subject_info)
        representative = data.get('representative')  # å‰ç«¯æ´¾ç³»å•èŠä¼šä¼ å…¥ä»£è¡¨äººç‰©å§“å
        if representative:
            # ç”¨ä»£è¡¨äººç‰©é£æ ¼è¦†ç›– personaï¼Œä¿æŒèº«ä»½ä¸€è‡´æ€§
            subject_info_override['persona'] = f"ä»¥{representative}çš„å£å»ä¸å†™ä½œé£æ ¼å›ç­”ï¼Œä¿æŒå…¶ç†è®ºç«‹åœºä¸æœ¯è¯­ä¹ æƒ¯ã€‚"
        
        current_llm = LLMClient() if (user_mode == 'llm') else None
        agent = SubjectAgent(subject_info_override, current_llm)
        answer = agent.deep_answer(question, context)
        
        # ç”Ÿæˆå»ºè®®é—®é¢˜ï¼ˆä½¿ç”¨åŒä¸€ä¸ª agent ä¿æŒé£æ ¼ä¸€è‡´ï¼‰
        suggestions = agent.generate_suggestions(question, answer)
        
        # è·å–å­¦ç§‘æ´¾åˆ«
        schools = subject_info.get('schools', [])
        
        # è¿è¡Œè·¯å¾„ä¿¡æ¯ï¼šæä¾›æ–¹ä¸æ˜¯å¦å›é€€æ¼”ç¤º
        llm_provider = agent.llm_client.provider if agent.llm_client else 'demo'
        used_demo = agent.last_used_demo
        
        # LLM_ONLY å¼ºåˆ¶ï¼šè‹¥æœ¬æ¬¡å›é€€äº†æ¼”ç¤ºï¼Œåˆ™ç›´æ¥è¿”å›é”™è¯¯
        if LLM_ONLY and used_demo:
            print(f"[LLM ONLY ENFORCE] deep_chat failed, provider={llm_provider}, subject={subject_name}, error={agent.last_error_message}")
            return jsonify({
                'success': False,
                'error': agent.last_error_message or 'LLMè°ƒç”¨å¤±è´¥ï¼Œå·²ç¦æ­¢æ¼”ç¤ºæ¨¡å¼',
                'llm_provider': llm_provider,
                'used_demo': True
            }), 503
        
        return jsonify({
            'success': True,
            'subject': subject_name,
            'icon': subject_info['icon'],
            'answer': answer,
            'suggestions': suggestions,
            'schools': schools,  # è¿”å›æ´¾åˆ«ä¿¡æ¯
            'demo_mode': user_mode == 'demo',
            'llm_provider': llm_provider,
            'used_demo': used_demo
        })
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/deep-chat-init', methods=['POST'])
def deep_chat_init():
    """
    åˆå§‹åŒ–æ·±å…¥å•èŠï¼šè·å–è¯¥å­¦ç§‘çš„å»ºè®®é—®é¢˜
    
    Request Body:
        {
            "subject_name": "å­¦ç§‘åç§°",
            "question": "åŸå§‹é—®é¢˜ï¼ˆç”¨äºç”Ÿæˆç›¸å…³å»ºè®®ï¼‰"
        }
    
    Response:
        {
            "success": true,
            "subject": "å­¦ç§‘åç§°",
            "suggestions": ["å»ºè®®é—®é¢˜1", "å»ºè®®é—®é¢˜2", "å»ºè®®é—®é¢˜3"]
        }
    """
    try:
        data = request.json
        subject_name = data.get('subject_name', '').strip()
        question = data.get('question', '').strip()
        
        if not subject_name:
            return jsonify({
                'success': False,
                'error': 'å­¦ç§‘åç§°ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # è·å–å­¦ç§‘ä¿¡æ¯
        subject_info = subject_library.get_subject_by_name(subject_name)
        if not subject_info:
            return jsonify({
                'success': False,
                'error': f'æœªæ‰¾åˆ°å­¦ç§‘ï¼š{subject_name}'
            }), 404
        
        # åˆ›å»ºAgentå¹¶ç”Ÿæˆå»ºè®®é—®é¢˜
        current_llm = llm_client if user_mode == 'llm' else None
        agent = SubjectAgent(subject_info, current_llm)
        suggestions = agent.generate_suggestions(question, '') if question else agent.generate_suggestions('', '')
        
        # è·å–æ´¾ç³»ä¿¡æ¯
        schools = subject_info.get('schools', [])
        
        return jsonify({
            'success': True,
            'subject': subject_name,
            'suggestions': suggestions,
            'schools': schools,
            'demo_mode': user_mode == 'demo'
        })
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/school-pk', methods=['POST'])
def school_pk():
    """
    å­¦ç§‘å†…æ´¾åˆ«PKï¼šåŒä¸€å­¦ç§‘å†…ä¸¤ä¸ªä¸åŒæ´¾åˆ«çš„è§‚ç‚¹å¯¹å†³
    
    Request Body:
        {
            "question": "ç”¨æˆ·çš„é—®é¢˜",
            "subject_name": "å­¦ç§‘åç§°",
            "school1": "æ´¾åˆ«1åç§°",
            "school2": "æ´¾åˆ«2åç§°",
            "round": 1,  // å½“å‰è½®æ¬¡ï¼Œé»˜è®¤1
            "history": []  // å†å²å¯¹è¯è®°å½•
        }
    
    Response:
        {
            "success": true,
            "question": "é—®é¢˜",
            "statements": [
                {"speaker": "school1", "content": "å‘è¨€å†…å®¹"},
                {"speaker": "school2", "content": "å‘è¨€å†…å®¹"},
                ...
            ],
            "round": 1,
            "has_more": true,
            "fun_fact": "å†·çŸ¥è¯†å½©è›‹"
        }
    """
    try:
        data = request.json
        question = data.get('question', '').strip()
        subject_name = data.get('subject_name', '').strip()
        school1_name = data.get('school1', '').strip()
        school2_name = data.get('school2', '').strip()
        current_round = data.get('round', 1)
        history = data.get('history', [])
        max_statements = data.get('max_statements', 10)  # æ–°å¢ï¼šä¸€è½®æœ€å¤šçš„å‘è¨€æ•°
        user_input = data.get('user_input', None)  # æ–°å¢ï¼šç”¨æˆ·è¾“å…¥
        
        if not question or not subject_name or not school1_name or not school2_name:
            return jsonify({
                'success': False,
                'error': 'é—®é¢˜ã€å­¦ç§‘å’Œä¸¤ä¸ªæ´¾åˆ«åç§°ä¸èƒ½ä¸ºç©º'
            }), 400
        
        if school1_name == school2_name:
            return jsonify({
                'success': False,
                'error': 'è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æ´¾åˆ«è¿›è¡ŒPK'
            }), 400
        
        # è·å–å­¦ç§‘ä¿¡æ¯
        subject_info = subject_library.get_subject_by_name(subject_name)
        if not subject_info:
            return jsonify({
                'success': False,
                'error': f'æœªæ‰¾åˆ°å­¦ç§‘ï¼š{subject_name}'
            }), 404
        
        # è·å–æ´¾åˆ«ä¿¡æ¯
        schools = subject_info.get('schools', [])
        school1_info = next((s for s in schools if s['name'] == school1_name), None)
        school2_info = next((s for s in schools if s['name'] == school2_name), None)
        
        if not school1_info or not school2_info:
            return jsonify({
                'success': False,
                'error': 'æœªæ‰¾åˆ°æŒ‡å®šçš„æ´¾åˆ«'
            }), 404
        
        # ç”Ÿæˆæœ¬è½®çš„å¯¹è¯ï¼ˆæ ¹æ® max_statements å‚æ•°ï¼‰
        statements = []
        statements_per_round = max_statements
        
        # å¦‚æœæœ‰ç”¨æˆ·è¾“å…¥ï¼ŒåŠ å…¥å†å²è®°å½•
        if user_input:
            history.append({
                'speaker': 'user',
                'name': 'ç”¨æˆ·',
                'icon': 'ğŸ‘¤',
                'content': user_input
            })
        
        current_llm = llm_client if user_mode == 'llm' else None
        
        for i in range(statements_per_round):
            if i % 2 == 0:
                # school1 å‘è¨€
                content = _generate_school_statement(
                    question, school1_info, subject_info, 
                    history, current_round, i//2 + 1, current_llm
                )
                statements.append({
                    'speaker': 'school1',
                    'name': school1_name,
                    'icon': school1_info['icon'],
                    'content': content
                })
            else:
                # school2 å‘è¨€
                content = _generate_school_statement(
                    question, school2_info, subject_info, 
                    history, current_round, i//2 + 1, current_llm
                )
                statements.append({
                    'speaker': 'school2',
                    'name': school2_name,
                    'icon': school2_info['icon'],
                    'content': content
                })
        
        # åˆ¤æ–­æ˜¯å¦è¿˜æœ‰æ›´å¤šè½®æ¬¡ï¼ˆæœ€å¤š3è½®ï¼Œå…±30å¥ï¼‰
        max_rounds = 3
        has_more = current_round < max_rounds
        
        response_data = {
            'success': True,
            'question': question,
            'subject_name': subject_name,
            'statements': statements,
            'round': current_round,
            'has_more': has_more,
            'school1': {
                'name': school1_name,
                'icon': school1_info['icon']
            },
            'school2': {
                'name': school2_name,
                'icon': school2_info['icon']
            },
            'demo_mode': user_mode == 'demo'
        }
        
        # å¦‚æœæ˜¯æœ€åä¸€è½®ï¼Œæ·»åŠ å†·çŸ¥è¯†å½©è›‹
        if not has_more:
            response_data['fun_fact'] = f"ğŸ’¡ æœ‰è¶£çš„æ˜¯ï¼Œ{school1_name}å’Œ{school2_name}è™½ç„¶è§‚ç‚¹ä¸åŒï¼Œä½†éƒ½ä¸°å¯Œäº†{subject_name}çš„ç†è®ºä½“ç³»ï¼è·¨æ´¾åˆ«æ€ç»´æ˜¯æ·±åº¦ç†è§£çš„å…³é”®ï¼"
        
        return jsonify(response_data)
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


def _generate_school_statement(question, school_info, subject_info, history, round_num, turn, llm_client):
    """ç”Ÿæˆæ´¾åˆ«çš„PKå‘è¨€"""
    if llm_client is None:
        # æ¼”ç¤ºæ¨¡å¼
        return _get_demo_school_statement(school_info, round_num, turn)
    
    try:
        # æ„å»ºæ´¾åˆ«ä¸“å±çš„prompt
        system_prompt = f"""ä½ æ˜¯{subject_info['name']}é¢†åŸŸä¸­{school_info['name']}å­¦æ´¾çš„ä»£è¡¨ã€‚

å­¦æ´¾ç‰¹ç‚¹ï¼š{school_info['description']}
ä»£è¡¨äººç‰©ï¼š{school_info['representative']}
æ ¸å¿ƒè§‚ç‚¹ï¼š{school_info['viewpoint']}

ä½ æ­£åœ¨ä¸{subject_info['name']}çš„å…¶ä»–å­¦æ´¾è¿›è¡Œå­¦æœ¯è¾©è®ºã€‚å½“å‰æ˜¯ç¬¬{round_num}è½®ç¬¬{turn}æ¬¡å‘è¨€ã€‚

è¦æ±‚ï¼š
1. ä¸€å¥è¯ï¼ˆ30-60å­—ï¼‰ï¼Œä½“ç°{school_info['name']}çš„ç‹¬ç‰¹ç«‹åœº
2. è§‚ç‚¹é²œæ˜ï¼Œç¬¦åˆè¯¥å­¦æ´¾çš„ç†è®ºç‰¹è‰²
3. å¯ä»¥é€‚å½“å›åº”å¯¹æ–¹è§‚ç‚¹
4. ä¿æŒå­¦æœ¯é£èŒƒï¼Œé¿å…äººèº«æ”»å‡»
"""
        
        history_text = ""
        if history:
            history_text = "\nå†å²å¯¹è¯ï¼š\n" + "\n".join([f"{h['name']}: {h['content']}" for h in history[-6:]])
        
        prompt = f"è¾©è®ºé—®é¢˜ï¼š{question}\n{history_text}\n\nè¯·ä»¥{school_info['name']}å­¦æ´¾çš„ç«‹åœºå‘è¡¨ä¸€å¥è§‚ç‚¹ï¼ˆ30-60å­—ï¼‰ã€‚"
        
        response = llm_client.generate_response(prompt, system_prompt, max_tokens=120, temperature=0.8)
        return response
    
    except Exception as e:
        return _get_demo_school_statement(school_info, round_num, turn)


def _get_demo_school_statement(school_info, round_num, turn):
    """ç”Ÿæˆæ¼”ç¤ºæ¨¡å¼çš„æ´¾åˆ«å‘è¨€"""
    templates = [
        f"ä»{school_info['name']}è§’åº¦ï¼Œ{school_info['viewpoint']}ã€‚",
        f"{school_info['representative']}æ—©å·²æŒ‡å‡ºï¼Œæˆ‘ä»¬åº”è¯¥{school_info['description']}ã€‚",
        f"æˆ‘å¿…é¡»å¼ºè°ƒï¼Œ{school_info['name']}çš„æ ¸å¿ƒåœ¨äºå¯¹è¿™ä¸ªé—®é¢˜çš„æ·±åˆ»ç†è§£ã€‚",
        f"æ ¹æ®{school_info['name']}çš„ç†è®ºæ¡†æ¶ï¼Œè¿™ä¸ªç°è±¡å¯ä»¥å¾—åˆ°æ›´å¥½çš„è§£é‡Šã€‚",
        f"è®©æˆ‘ä»¬å›åˆ°{school_info['description']}ï¼Œè¿™æ‰æ˜¯é—®é¢˜çš„å…³é”®æ‰€åœ¨ã€‚"
    ]
    return templates[(round_num - 1) * 5 + turn - 1] if ((round_num - 1) * 5 + turn - 1) < len(templates) else templates[0]


@app.route('/api/pk', methods=['POST'])
def subject_pk():
    """
    å­¦ç§‘PKï¼šä¸¤ä¸ªå­¦ç§‘è½®æµå¯¹è¯è¾©è®º
    
    Request Body:
        {
            "question": "ç”¨æˆ·çš„é—®é¢˜",
            "subject1": "å­¦ç§‘1åç§°",
            "subject2": "å­¦ç§‘2åç§°",
            "round": 1,  // å½“å‰è½®æ¬¡ï¼Œé»˜è®¤1
            "history": []  // å†å²å¯¹è¯è®°å½•
        }
    
    Response:
        {
            "success": true,
            "question": "é—®é¢˜",
            "statements": [
                {"speaker": "subject1", "content": "å‘è¨€å†…å®¹"},
                {"speaker": "subject2", "content": "å‘è¨€å†…å®¹"},
                ...
            ],
            "round": 1,
            "has_more": true,  // æ˜¯å¦è¿˜æœ‰æ›´å¤šè½®æ¬¡
            "fun_fact": "å†·çŸ¥è¯†å½©è›‹"  // æœ€åä¸€è½®æ‰è¿”å›
        }
    """
    try:
        data = request.json
        question = data.get('question', '').strip()
        subject1_name = data.get('subject1', '').strip()
        subject2_name = data.get('subject2', '').strip()
        current_round = data.get('round', 1)
        history = data.get('history', [])
        
        if not question or not subject1_name or not subject2_name:
            return jsonify({
                'success': False,
                'error': 'é—®é¢˜å’Œä¸¤ä¸ªå­¦ç§‘åç§°ä¸èƒ½ä¸ºç©º'
            }), 400
        
        if subject1_name == subject2_name:
            return jsonify({
                'success': False,
                'error': 'è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„å­¦ç§‘è¿›è¡ŒPK'
            }), 400
        
        # è·å–ä¸¤ä¸ªå­¦ç§‘ä¿¡æ¯
        subject1_info = subject_library.get_subject_by_name(subject1_name)
        subject2_info = subject_library.get_subject_by_name(subject2_name)
        
        if not subject1_info or not subject2_info:
            return jsonify({
                'success': False,
                'error': 'æœªæ‰¾åˆ°æŒ‡å®šçš„å­¦ç§‘'
            }), 404
        
        # åˆ›å»ºä¸¤ä¸ªAgent
        current_llm = llm_client if user_mode == 'llm' else None
        agent1 = SubjectAgent(subject1_info, current_llm)
        agent2 = SubjectAgent(subject2_info, current_llm)
        
        # ç”Ÿæˆæœ¬è½®çš„å¯¹è¯ï¼ˆæ ¹æ® max_statements å‚æ•°ï¼‰
        statements = []
        statements_per_round = max_statements
        
        for i in range(statements_per_round):
            if i % 2 == 0:
                # subject1 å‘è¨€
                content = agent1.generate_pk_statement(question, history, round_num=current_round, turn=i//2 + 1)
                statements.append({
                    'speaker': 'subject1',
                    'name': subject1_name,
                    'icon': subject1_info['icon'],
                    'content': content
                })
            else:
                # subject2 å‘è¨€
                content = agent2.generate_pk_statement(question, history, round_num=current_round, turn=i//2 + 1)
                statements.append({
                    'speaker': 'subject2',
                    'name': subject2_name,
                    'icon': subject2_info['icon'],
                    'content': content
                })
        
        # åˆ¤æ–­æ˜¯å¦è¿˜æœ‰æ›´å¤šè½®æ¬¡ï¼ˆæœ€å¤š3è½®ï¼Œå…±30å¥ï¼‰
        max_rounds = 3
        has_more = current_round < max_rounds
        
        response_data = {
            'success': True,
            'question': question,
            'statements': statements,
            'round': current_round,
            'has_more': has_more,
            'subject1': {
                'name': subject1_name,
                'icon': subject1_info['icon']
            },
            'subject2': {
                'name': subject2_name,
                'icon': subject2_info['icon']
            },
            'demo_mode': user_mode == 'demo'
        }
        
        # å¦‚æœæ˜¯æœ€åä¸€è½®ï¼Œæ·»åŠ å†·çŸ¥è¯†å½©è›‹
        if not has_more:
            response_data['fun_fact'] = _generate_fun_fact(subject1_name, subject2_name, question)
        
        return jsonify(response_data)
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


def _generate_fun_fact(subject1, subject2, question):
    """ç”Ÿæˆè·¨å­¦ç§‘å†·çŸ¥è¯†å½©è›‹"""
    fun_facts = [
        f"ğŸ’¡ æœ‰è¶£çš„æ˜¯ï¼Œ{subject1}å’Œ{subject2}åœ¨å†å²ä¸Šæ›¾ç»æ˜¯åŒä¸€é—¨å­¦ç§‘çš„åˆ†æ”¯ï¼",
        f"ğŸ’¡ ç ”ç©¶å‘ç°ï¼ŒåŒæ—¶ä»{subject1}å’Œ{subject2}è§’åº¦æ€è€ƒé—®é¢˜çš„äººï¼Œåˆ›é€ åŠ›æé«˜äº†37%ï¼",
        f"ğŸ’¡ è®¸å¤šè¯ºè´å°”å¥–å¾—ä¸»éƒ½åŒæ—¶ç²¾é€š{subject1}å’Œ{subject2}ï¼Œè·¨å­¦ç§‘æ€ç»´æ˜¯åˆ›æ–°çš„å…³é”®ï¼",
        f"ğŸ’¡ åœ¨å¤å¸Œè…Šï¼Œ{subject1}å’Œ{subject2}è¢«è®¤ä¸ºæ˜¯ç†è§£ä¸–ç•Œçš„ä¸¤ä¸ªäº’è¡¥è§†è§’ã€‚",
        f"ğŸ’¡ æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œ{subject1}å’Œ{subject2}çš„ç»“åˆå‚¬ç”Ÿäº†è®¸å¤šå‰æ²¿é¢†åŸŸçš„çªç ´ï¼"
    ]
    return random.choice(fun_facts)


if __name__ == '__main__':
    print("ğŸ Let's Talk - å¤šå­¦ç§‘è§†è§’Agent")
    print("=" * 50)
    if demo_mode:
        print("âš ï¸  æ¼”ç¤ºæ¨¡å¼ï¼šä½¿ç”¨æ¨¡æ‹Ÿå›ç­”")
    else:
        print("âœ… LLMæ¨¡å¼ï¼šä½¿ç”¨çœŸå®API")
    print("=" * 50)
    print("\nğŸŒ è®¿é—®åœ°å€: http://localhost:5002")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡\n")
    
    app.run(debug=True, host='0.0.0.0', port=5002)

